# NHS ACUTE TRUST DAILY NUMBER OF PEADIATRIC EMERGENCY ATTENDANCES NEXT 28 DAYS FORECAST REPORT


&copy; HPDM097: 710053015: 2022


# Executive summary
While doing this forecasting project, my main goal was to recommend a suitable forecasting method for an NHS acute trust and provide a twenty-eight days forecast of the daily number of pediatric emergency attendance. After a careful evaluation and comparison of the suitable method with a naive benchmark on a twenty-eight days forecast result, using the root mean square error score(RMSE) score of these methods on test data, I decide which method is the best for the NHS Trust to forecast a daily number of pediatric emergency attendances at the hospital. The least RMSE value shows which method would be useful at most for their data to support them with planning their staffing decision to sufficiently handle pediatric emergency attendances. which was “Prophet” as it produced the lowest error score.

# Introduction.
In this forecast project I will implement, cross validate, and test Prophet forecasting method, and compare it with a NAIVE1 benchmark forecasting method on a twenty-eight days forecast horizon using their root mean square error(RMSE), scoring on the test dataset.
### Aims and Objectives.
* To produce a twenty-eight days forecast on a daily peadiatric attendances at a hospital emergency department.
* To evaluate and compare between Prophet and the NIAVE1 benchmark which one would be best  for this task.
* To recommend a forecasting method for a NHS Acute Trust for forecasting peadiatric emergency attendances at the hospital.

### The Data
A Time Series Data set with "date" and "paed_ed_attends" columns containing 1056 observation of daily peadiatric attendance at a NHS acute trust collected from April 2014 to February 2017 was provided for this practical.







# Planed Analyses and Methods


## 1.   Loading time series data into the colab notebook.
The dataset for this project is hosted on a github repositoey and it was accessed through its url uisng pandas o download it into google-colab while setting the frequency of the data in the datafram to 'D' as these were data collected on a daily frequency. 




```python
#@title Imports (RUN ME!) { display-mode: "form" }
# installing package forecast_tools for the forecasting process.
#!pip install forecast_tools
# installing prophet
#!pip install prophet
# importing pandas library for downloading and analyzing the dataset
import pandas as pd 
# importing numpy for performing numeric calculations and working with arrays and or series.
import numpy as np
# importing adfuller to perfom dicky fuller test for stationarity
from statsmodels.tsa.stattools import adfuller
from numpy.core.shape_base import block
from pandas.core.algorithms import diff
# Importing performance metrics measures
from forecast_tools.metrics import forecast_errors
# Importing all the baseline bench models
from forecast_tools.baseline import baseline_estimators
# Importing Naive1 from the baseline estimators
from forecast_tools.baseline import Naive1, SNaive
# importing matplotlib to help with the plotting and creating graphs
import matplotlib.pyplot as plt
# importing statmodels api for accessing some functions and model inside the stats model
import statsmodels.api as sm
plt.style.use('ggplot')
%matplotlib inline


```


```python
file_url = 'https://raw.githubusercontent.com/N-Sam/forecast-lab/main/paediatrics_train.csv'
```


```python
df_timeseries = pd.read_csv(file_url, parse_dates= True, index_col='date')
df_timeseries.index.freq = 'D'
```

## 2.   Exploratory data analysis.
Exploratory data analysis was performed on the data set to get a clear understanding of the dataset and assess for the existence of missing values or invalid data format, assess for trend, seasonality and auto-correllaion in the series and to make the series stationary before using it for the forecast.

### Preliminary Analyses.




```python
# getting to know the number of rows and columns in the dataset
df_timeseries.shape
```




    (1056, 1)




```python
# getting to know the total different column in the dataframe and their data type.
df_timeseries.info()
```

    <class 'pandas.core.frame.DataFrame'>
    DatetimeIndex: 1056 entries, 2014-04-01 to 2017-02-19
    Freq: D
    Data columns (total 1 columns):
     #   Column           Non-Null Count  Dtype
    ---  ------           --------------  -----
     0   paed_ed_attends  1056 non-null   int64
    dtypes: int64(1)
    memory usage: 16.5 KB



```python
# viewing the index of the dataset
df_timeseries.index
```




    DatetimeIndex(['2014-04-01', '2014-04-02', '2014-04-03', '2014-04-04',
                   '2014-04-05', '2014-04-06', '2014-04-07', '2014-04-08',
                   '2014-04-09', '2014-04-10',
                   ...
                   '2017-02-10', '2017-02-11', '2017-02-12', '2017-02-13',
                   '2017-02-14', '2017-02-15', '2017-02-16', '2017-02-17',
                   '2017-02-18', '2017-02-19'],
                  dtype='datetime64[ns]', name='date', length=1056, freq='D')




```python
# checking if there is any null value in the data frame
df_timeseries.isnull().any()
```




    paed_ed_attends    False
    dtype: bool




```python
# getting the minimum starting index of the data frame
df_timeseries.index.min()
```




    Timestamp('2014-04-01 00:00:00', freq='D')




```python
# getting the maximum index of the data frame
df_timeseries.index.min()
```




    Timestamp('2014-04-01 00:00:00', freq='D')




```python
# viewing the first five rows of the data frame
df_timeseries.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paed_ed_attends</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2014-04-01</th>
      <td>47</td>
    </tr>
    <tr>
      <th>2014-04-02</th>
      <td>46</td>
    </tr>
    <tr>
      <th>2014-04-03</th>
      <td>47</td>
    </tr>
    <tr>
      <th>2014-04-04</th>
      <td>48</td>
    </tr>
    <tr>
      <th>2014-04-05</th>
      <td>52</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_timeseries.plot(figsize=(12,4))
```




    <AxesSubplot:xlabel='date'>




    
![png](output_16_1.png)
    


From the above plot, we can notice that time-series has some-kind of additive effect which seems to be increasing with time-period. We can see that there is a slight trend and strong seasonality effects which is amplifying over time.

Below I also plotted auto-correlation plot for time-series data as well. This plot was meant to helped understand whether present values of time-series were positively correlated, negatively correlated or not related at all with past values. statsmodels library provided a ready to use method plot_acf for this. 





```python
from statsmodels.graphics.tsaplots import plot_acf


plot_acf(df_timeseries);
```


    
![png](output_18_0.png)
    


I notice from the above chart that after 15 lags, the line gets inside confidence interval (the pink shaded area). This can be due to auto correlation and seasonality in the time series.

Using the utility funcion seasonal_decompose in the Python statsmodel module the time-series was decomposed to see various components of trends, seasonality and residuals in the time-series visually.


```python
# importing seasonal_decompose from statsmodels to decompose the series
from statsmodels.tsa.seasonal import seasonal_decompose

```


```python
decompose_result = seasonal_decompose(df_timeseries, model="additive")

trend = decompose_result.trend
seasonal = decompose_result.seasonal
residual = decompose_result.resid

fig = decompose_result.plot();
fig.set_size_inches(12,8)
```


    
![png](output_22_0.png)
    


We can notice trend and seasonality components separately as well as residual components.

some helper functions were defined below in a colapsible cell to reduced the length of the notebook. it can be viewed by clicking view code link on the cell.


```python
#@title Helper Functions (RUN ME!, VIEW ME!) { display-mode: "form" }

# A function to split the time series into training and testsets

def split_time_series(df, test_size):
	"""
	This function split the time series datafarme into
    a training and test set to be used
	later in validation

	Params:
    -df (dataframe)
		-test_size (float in percentage)
	
	Outputs:
		-training_df
		-test_df
	"""
	train_percent = len(df)/ len(df) - test_size
	train_len = int(train_percent * len(df))
	train_df = df[:train_len]
	test_df = df[train_len:]

	return train_df, test_df

# A helper function for ploting naive predictions
def plot_naive_prediction(df, pred):
	"""
	This function helps in plotting naive prediction
	by converting the predicted values into a pandas dataframe.

	Params:
		-df (training dataset)
		-pred (predictions)

	"""
	start = pd.date_range(start=df.index.max(), periods=2, freq='D').max()
	index = pd.date_range(start=start, periods=len(pred), freq=df.index.freq)
 
	return pd.DataFrame(pred, index=index)

# A function to generate a first degree differenced series
def diference_ts(timeseries):
    ts_diff = timeseries - timeseries.shift()
    ax1 = plt.subplot(121)
    ts_diff.plot(figsize=(8,4), color="tab:red", title="Passed series & Differenced Time-Series", ax=ax1);
    ax2 = plt.subplot(122)
    df_timeseries.plot(figsize=(12,4), color="tab:red", title="Original Values", ax=ax2);
    return ts_diff
# invert differenced forecast

#Funtion for testing stationarity
def test_stationarity(timeseries, window=12):
    movingAv = timeseries.rolling(window=window).mean()
    movingSTD = timeseries.rolling(window=window).std()
    # plotting the rolling meanand std
    originalseries = plt.plot(timeseries, color="blue", label="Passed series series")
    mean = plt.plot(movingAv, color="red", label="Moving Average")
    std = plt.plot(movingSTD, color="green", label="Moving Standard deviation")
    plt.legend(loc="best")
    plt.title("Rolling Mean And Standard deviation")    
    plt.show(block=False)
    print()
    print('performing dicky-fuller test')
    
    dftest = adfuller(timeseries['paed_ed_attends'].dropna().values, autolag = 'AIC')
    dfoutput = pd.Series(dftest[0:4], index=['Test Statistics', 'P-Value', 'Num Lag used', 'Number of observation used'])

    for key, val in dftest[4].items():
        dfoutput['Critical value (%s)'%key] = val
    print(dfoutput)

# A rolling forecast function
def rolling_forecast_origin(train, min_train_size, horizon):
    '''
    Rolling forecast origin generator function.
    
    Params:
        -train (dataframe used to fit the model).
        -min_train_size (minimum size required to train the model).
        -horizon (the prediction interval to be produced).
    Outputs:
        -train df
        -test df
    '''
    for i in range(len(train) - min_train_size - horizon + 1):
        split_train = train[:min_train_size+i]
        split_test = train[min_train_size+i:min_train_size+i+horizon]
        yield split_train, split_test

# A function to cross validate our model
def cross_validate(model, cv, scores=[], horizon=28):
    from forecast_tools.metrics import root_mean_squared_error
    """
    This Function perform cross validation on a model.

    Params:
        -model (object)
    Output:
        -mean cross validation error score
    """

    for train_fold, test_fold in cv:
        # this could be any model
        #print(F'Train Fold {train_fold}')
        #print(F'Test Fold {test_fold}')
        model.fit(train_fold)
        preds = model.predict(horizon)
        
        # this could be any error measure
        score = root_mean_squared_error(test_fold, preds)
        scores.append(score)
        #print(F'Score: {score}')
        #print(preds)
     
    print(np.array(scores).mean())
# A function to make prophet dataframe

def make_prophet_data(y_train):
    '''
    This function converts a timeseries series or
    a timeseries dataframe into a prophet format for modeling.
    Parameters:
    ---------
    df_train: pandas dataframe or series with datetime index with only
        the target variable as column.
        
    outputs:
    --------
        pd.DataFrame in Prophet format 
        with additional column ds added.
    '''
    prophet_df = pd.DataFrame(y_train.index)
    prophet_df['y'] = y_train.to_numpy()
    prophet_df.columns = ['ds', 'y']
    return prophet_df

# A function to create prophet future dataframe
def make_future_df(df_train, df_test, horizon):
    '''
    This function creates a test dataset from the training and test
    timeseries dataframe into a prophet future dataframe for testing.
    Parameters:
         -df_train (training dataframe)
         -df_test (holdout test data)
         -horizon (prediction period)
    ---------
    df_train: pandas dataframe or series with datetime as only
        the only column.
        
    outputs:
    --------
        pd.DataFrame in Prophet format futur df. 
        
    '''
    values = df_train.index.to_list()[0:] + df_test.index.to_list()[0:28]
    p_f_df = pd.DataFrame(values)
    p_f_df.columns = ['ds']

    return p_f_df

# Function for measuring prophet pointforecast error
def calculate_prophet_error(df, forecast):
    err = {}
    """
    This function calculates prophet point forcast error.

    Params:
        - df (prophet predictions)
        - forecast (prophet forecast)

    Output:
        -prediction errors
    """
    y_true = df['paed_ed_attends'][0:28].values
    y_pred = forecast['yhat'][835:863].values
    matrics = forecast_errors(y_true, y_pred)
    # err['mae'] = mean_absolute_error(y_true, y_pred)
    # err['rmse'] = root_mean_squared_error(y_true, y_pred)
    # err['smape'] = symmetric_mean_absolute_percentage_error(y_true, y_pred)
   

    for key, val in matrics.items():
         print(f'{key}: {val}')

#A helper function to recover original dataframe
def recover_original(ts_diff, detrended_df, timeseries):
    """
    This functions recover the original dataframe from 
    the detrended dataframe and differenced dataframe

    Params:
        -ts_diff(differenced series)
        -ori_df(original timeseries)
    """
    rolling_mean = timeseries.rolling(window = 12).mean()
    ts_diff = ts_diff.dropna()
    detrended_df = detrended_df.dropna()
    detrended_df = detrended_df + ts_diff
    rolling_mean = rolling_mean.dropna()
    ori_df = detrended_df + rolling_mean
    
    return ori_df

# A helper function for ploting prediction interval
def plot_prediction_intervals(train, preds, intervals, test=None):
    '''
    Helper function to plot training data, point preds
    and 3 sets of prediction intevals with 3 sets of prediction interval
    
    Params:
        -train (the dataframe used in fitting the model)
        -pred, (the predicted values of the model)
        -intervals theprediction intervals returned.
    Output:
        -plot of the predicted values with their respective 
        predictions intervals.
    '''
    ax = train.plot(figsize=(12,4))

    mean = plot_naive_prediction(train, preds)
    intervals_80 = plot_naive_prediction(train, intervals[0])
    intervals_90 = plot_naive_prediction(train, intervals[1])
    intervals_95 = plot_naive_prediction(train, intervals[2])

    mean.plot(ax=ax, label='point forecast')

    ax.fill_between(intervals_80.index, mean[0], intervals_80[1], 
                    alpha=0.2,
                    label='80% PI', color='yellow');

    ax.fill_between(intervals_80.index,mean[0], intervals_80[0], 
                    alpha=0.2,
                    label='80% PI', color='yellow');

    ax.fill_between(intervals_80.index,intervals_80[1], intervals_90[1],intervals_95[1], 
                    alpha=0.1,
                    label='90% PI', color='green');

    ax.fill_between(intervals_80.index,intervals_80[0], intervals_90[0], intervals_95[0],
                    alpha=0.1,
                    label='90% PI', color='green');
    
    ax.fill_between(intervals_80.index,intervals_80[1], intervals_90[1],  intervals_95[1], 
                    alpha=0.05,
                    label='95% PI', color='white');

    ax.fill_between(intervals_80.index,intervals_80[0], intervals_90[0],  intervals_95[0],
                    alpha=0.05,
                    label='95% PI', color='white');
    
   
    ax.legend(['train', 'point forecast', '80%PI', '90%PI', '95%PI'], loc=2)
   
```

### Checking Whether Time-Series is Stationary or Not 
A check was done to determine whether the mean, variance and auto-covariance are independent of time. these components, mean, variance and auto-covariance were checked using moving window functions available with pandas. Dicky-fuller test available with statsmodels was also used to check the stationarity of time-series, all were inplemented in a helper function called test_stationarity. If time-series was not stationary then I needed to make it stationary, beacuse the models and forecasting process require a stationary series.
Below I have taken an average over moving window of 12 samples. We noticed from the above plots that there are seasonality and some slight trend in the time-series. Different window sizes for testing purposes were tried.


```python
test_stationarity(df_timeseries, 12)

```


    
![png](output_27_0.png)
    


    
    performing dicky-fuller test
    Test Statistics                 -5.114570
    P-Value                          0.000013
    Num Lag used                    15.000000
    Number of observation used    1040.000000
    Critical value (1%)             -3.436653
    Critical value (5%)             -2.864323
    Critical value (10%)            -2.568252
    dtype: float64



```python
test_stationarity(df_timeseries, 28)

```


    
![png](output_28_0.png)
    


    
    performing dicky-fuller test
    Test Statistics                 -5.114570
    P-Value                          0.000013
    Num Lag used                    15.000000
    Number of observation used    1040.000000
    Critical value (1%)             -3.436653
    Critical value (5%)             -2.864323
    Critical value (10%)            -2.568252
    dtype: float64



```python
test_stationarity(df_timeseries, 365)
```


    
![png](output_29_0.png)
    


    
    performing dicky-fuller test
    Test Statistics                 -5.114570
    P-Value                          0.000013
    Num Lag used                    15.000000
    Number of observation used    1040.000000
    Critical value (1%)             -3.436653
    Critical value (5%)             -2.864323
    Critical value (10%)            -2.568252
    dtype: float64


from the three charts we can see that over a year, the mean and the standard deviation are fairly distributed, but there are trends and seasonality components in the monthly and in the next 28 days.

The above results were interpreted based on p-values of the result taking.
* **p-value > 0.05** - to imply that time-series is **non-stationary**.
* **p-value <=0.05** - to imply that time-series is **stationary**.

As we can see from the above results that p-value is **1.31e-05** signifficantly less than **0.05** hence our time-series is  stationary.

### Removing trend using Logged Transformation
To apply log transformation, the log of each individual value of time-series data were taken.


```python
logged_df = df_timeseries["paed_ed_attends"].apply(lambda x : np.log(x))

ax1 = plt.subplot(121)
logged_df.plot(figsize=(12,4) ,color="tab:red", title="Log Transformed Values", ax=ax1);
ax2 = plt.subplot(122)
df_timeseries.plot(color="tab:red", title="Original Values", ax=ax2);
```


    
![png](output_33_0.png)
    


From the above first chart, It can be seen that there was a reduced variance of time-series data. We can look at y-values of original time-series data and log-transformed time-series data to conclude that the variance of time-series is reduced.

checking whether the transfromation was successful or not was done by checking individual components of time-series by decomposing it as shown below.


```python
decompose_result = seasonal_decompose(logged_df)

decompose_result.plot();
```


    
![png](output_35_0.png)
    


### Applying Power Transformations 
Power transformation was applied on the 'paed_ed_attends' column by extracting the square root of the individaul values to remove trend as below.


```python
powered_df = df_timeseries["paed_ed_attends"].apply(lambda x : x ** 0.5)

ax1 = plt.subplot(121)
powered_df.plot(figsize=(12,4), color="tab:red", title="Powered Transformed Values", ax=ax1);
ax2 = plt.subplot(122)
df_timeseries.plot(figsize=(12,4), color="tab:red", title="Original Values", ax=ax2);
```


    
![png](output_37_0.png)
    


From the above first chart, we can see the variance of time-series data was reduced. We can look at y-values of original time-series data and power-transformed time-series data to conclude that the variance of time-series is reduced.

To check whether it was successful or not, individual components of time-series were decomposed as we had done previously.


```python
decompose_result = seasonal_decompose(powered_df)

decompose_result.plot();
```


    
![png](output_39_0.png)
    


### Applying Moving Window Functions
Rolling mean over a period of 12 months was calculated and subtracted from original time-series to get de-trended time-series.


```python
rolling_mean = df_timeseries.rolling(window = 12).mean()
paed_rolled_detrended = df_timeseries - rolling_mean

ax1 = plt.subplot(121)
paed_rolled_detrended.plot(figsize=(12,4),color="tab:red", title="Differenced With Rolling Mean over 12 month", ax=ax1);
ax2 = plt.subplot(122)
df_timeseries.plot(figsize=(12,4), color="tab:red", title="Original Values", ax=ax2);
```


    
![png](output_41_0.png)
    


From the above the first chart, it was seen that transformation seem to have removed trend from time-series data.

checking whether it was successful or not by was done by checking individual components of time-series by decomposing it.

After applying the above transformations, we can see that moving window function seems to have done a good job in removing the trend than other methods. To confirm it further whether it actually did good, the different component of the series was removed and a check for stationarity of time-series was done using dicky-fuller test.


```python
decompose_result = seasonal_decompose(paed_rolled_detrended.dropna())

decompose_result.plot();
```


    
![png](output_44_0.png)
    


## Removing Seasonality 
To remove seasonality differencing technique was used differencing over the de-trended time-series calculated above.

### Differencing Over rolled mean Transformed Time-Series
Differencing was applied to detrened transformed time-series by shifting it's value by 1 period and subtracting it from original log-transformed time-series


```python
ts_diff = diference_ts(paed_rolled_detrended)
```


    
![png](output_47_0.png)
    


From the first chart we see that the overall mean of the time series data has been reduced. Again a test was perormed to check whether our time-series is still stationary as of now by applying the dicky-fuller test which we had applied above.


```python
test_stationarity(paed_rolled_detrended)
```


    
![png](output_49_0.png)
    


    
    performing dicky-fuller test
    Test Statistics              -7.947558e+00
    P-Value                       3.189689e-12
    Num Lag used                  1.300000e+01
    Number of observation used    1.031000e+03
    Critical value (1%)          -3.436709e+00
    Critical value (5%)          -2.864347e+00
    Critical value (10%)         -2.568265e+00
    dtype: float64


From our dicky-fuller test results, we can confirm that time-series is **stationary** due to the p-value of 3.19e-12 signifficantly less than 0.05, and from the chart on the left it shows the moving average distributed between 5 and -5.

## Fitting Naive 1 Forecast As a Benchmark Model
To provide a benchamrk, Naive1 forecast from the baseline estimators was fitted , this model simply takes the last value in the time series and extrapolates it forward over the forecast horizon. as seen below from the predicted values.

**Naive Forecast = Last value in the time series**

Mathematically notated as:

$\hat{y}_{T+h|T} =y_t$ .......................................................................................(1)

To test and evaluate the model, some dataset were held back and the model was not trained on it but only provided at testing process of the model. This was done to simulate real forecasting conditions and check a models accuracy on unseen data. I didn't want the model to know what it looks like as that would have introduced bias into the forecasting process and overfiting the model to data.


```python
ts_diff = ts_diff.dropna()
ts_diff.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paed_ed_attends</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2014-04-13</th>
      <td>-6.583333</td>
    </tr>
    <tr>
      <th>2014-04-14</th>
      <td>10.416667</td>
    </tr>
    <tr>
      <th>2014-04-15</th>
      <td>-4.166667</td>
    </tr>
    <tr>
      <th>2014-04-16</th>
      <td>-2.833333</td>
    </tr>
    <tr>
      <th>2014-04-17</th>
      <td>9.666667</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_train, df_test = split_time_series(ts_diff, 0.2)
print(len(df_train))
print(len(df_test))
```

    835
    209



```python
model_1 = Naive1()
model_1.fit(df_train['paed_ed_attends'])
```

The prediction interval and a 28 days predicted value were produced in a variable y_intervals and y_preds respectively.


```python
y_preds, y_intervals = model_1.predict(horizon=28, return_predict_int=True, alpha=[0.2,0.1,0.05])
```


```python
# Displaying the preicted next 28 days values
y_preds
```




    array([5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
           5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25, 5.25,
           5.25, 5.25, 5.25, 5.25, 5.25, 5.25])




```python
df_train.tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paed_ed_attends</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-07-21</th>
      <td>-7.250000</td>
    </tr>
    <tr>
      <th>2016-07-22</th>
      <td>2.750000</td>
    </tr>
    <tr>
      <th>2016-07-23</th>
      <td>-6.000000</td>
    </tr>
    <tr>
      <th>2016-07-24</th>
      <td>2.333333</td>
    </tr>
    <tr>
      <th>2016-07-25</th>
      <td>5.250000</td>
    </tr>
  </tbody>
</table>
</div>




```python
# from forecast_tools.metrics import forecast_errors

forecast_errors(df_test, y_preds)
```

    /home/ubuntu/anaconda3/envs/hds_forecast/lib/python3.8/site-packages/forecast_tools/metrics.py:84: RuntimeWarning: divide by zero encountered in true_divide
      return np.mean(np.abs((y_true - y_pred) / y_true)) * 100





    {'me': -5.275518341307814,
     'mae': 9.399920255183412,
     'mse': 130.28811137692716,
     'rmse': 11.414381778130918,
     'mape': inf,
     'smape': 139.44740726501047}



From the error scores, we can see that rmse give a more sensible error score than other measures, hence we will based our evaluation and comparison on it.


```python
df_train_ori = recover_original(df_train, paed_rolled_detrended, df_timeseries).dropna()
df_train_ori.astype(int).tail()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>paed_ed_attends</th>
    </tr>
    <tr>
      <th>date</th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2016-07-21</th>
      <td>44</td>
    </tr>
    <tr>
      <th>2016-07-22</th>
      <td>56</td>
    </tr>
    <tr>
      <th>2016-07-23</th>
      <td>42</td>
    </tr>
    <tr>
      <th>2016-07-24</th>
      <td>52</td>
    </tr>
    <tr>
      <th>2016-07-25</th>
      <td>61</td>
    </tr>
  </tbody>
</table>
</div>



## Cross validating Naive1 forecast.


```python
train1=ts_diff['paed_ed_attends']
cv_rolling = rolling_forecast_origin(train1, min_train_size=100, horizon=28)
cross_validate(model_1, cv_rolling)
```

    13.618276673223207


The fittted values were plotted against the differenced data as shown below to see how well it fit.


```python
ax = ts_diff.plot(figsize=(12,4))
model_1.fittedvalues.plot(ax=ax, linestyle=':', color="green")
plot_naive_prediction(ts_diff, y_preds).plot(ax=ax)
ax.legend(['df_train', 'Model_1'])
```




    <matplotlib.legend.Legend at 0x7f8d4cbaa640>




    
![png](output_66_1.png)
    


From the above plot we can see the naive1 fitted values plotted againts the original timeseries, the red portion of the plot is representing the test set that naive1 was not trained on, and the blue line is showing naive1 forecast for the next 28 dasy.

The prediction interval of the Naive1 model was plotted as seen below.


```python
plot_prediction_intervals(df_train, y_preds, y_intervals)
```


    
![png](output_69_0.png)
    


### Fitting Seasonal Naive

In an attempt to take care of the seasonality in the data, I fitted a seasonal Naive model to explore weekly seasonality and see if it might perform better, the point forecast, cross validation error was taken and compared with that of the naive model.


```python
snf = SNaive(period=7)
snf.fit(df_train)
sy_preds, sy_intervals = snf.predict(horizon=28, return_predict_int=True, 
                                    alpha=[0.2, 0.1, 0.05])
```


```python
sy_preds
```




    array([-19.        ,  10.25      ,  -7.25      ,   2.75      ,
            -6.        ,   2.33333333,   5.25      , -19.        ,
            10.25      ,  -7.25      ,   2.75      ,  -6.        ,
             2.33333333,   5.25      , -19.        ,  10.25      ,
            -7.25      ,   2.75      ,  -6.        ,   2.33333333,
             5.25      , -19.        ,  10.25      ,  -7.25      ,
             2.75      ,  -6.        ,   2.33333333,   5.25      ])




```python
ax = df_train.plot(figsize=(12,4))
snf.fittedvalues.plot(ax=ax, linestyle='-.')
plot_naive_prediction(df_train, sy_preds).plot(ax=ax)
ax.legend(['train','Fitted Model', 'SNaive Forecast'])
```




    <matplotlib.legend.Legend at 0x7f8d443d0700>




    
![png](output_73_1.png)
    



```python
forecast_errors(df_test, sy_preds)
```

    /home/ubuntu/anaconda3/envs/hds_forecast/lib/python3.8/site-packages/forecast_tools/metrics.py:84: RuntimeWarning: divide by zero encountered in true_divide
      return np.mean(np.abs((y_true - y_pred) / y_true)) * 100





    {'me': 1.6411483253588524,
     'mae': 10.99920255183413,
     'mse': 187.40038543328015,
     'rmse': 13.689426044698884,
     'mape': inf,
     'smape': 140.8387448388735}




```python
plot_prediction_intervals(df_train, sy_preds, sy_intervals)
```


    
![png](output_75_0.png)
    


### Cross validating SNaive model.


```python
scv_rolling = rolling_forecast_origin(train1, min_train_size=100, horizon=28)
cross_validate(snf, scv_rolling)
```

    13.554668521755556


## Fitting prophet model.

Prphet model was fitted by first creating a Prophet object as ``` model = Prophet(interval_width=0.95, daily_seasonality=False)```,using the same training dataset and tested on the same dataset with cross validation to make a fair comparison between the benchmark model and prophet method.



```python
import prophet

from prophet import Prophet
from prophet.plot import (plot_plotly, plot_components_plotly,
                          add_changepoints_to_plot)
```


```python
from prophet.diagnostics import cross_validation, performance_metrics
from prophet.plot import plot_cross_validation_metric
```


```python
prophet_train = make_prophet_data(df_train)
```


```python
model_p = Prophet(interval_width=0.95, daily_seasonality=False)
model_p.fit(prophet_train)
```

    Initial log joint probability = -55.3331





    <prophet.forecaster.Prophet at 0x7f8d4432b850>



        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       511.347   2.41836e-07       91.4268      0.2776           1      124   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         110       511.347   5.31309e-09        96.307      0.3337      0.3337      138   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance


**Testing Prophet model**,
To test the prophet model on our test data set held out, the future data set for making prediction was made from the training and test data set. to confirm that there was no variation, a check was mad against the builtin prophet method ```make_future_dataframe(periods=28)``` and he same data frame for evaluation was produced.


```python
p_f_df = make_future_df(df_train, df_test, 28)
p_f_df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-04-13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-04-14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-04-15</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-04-16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-04-17</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>858</th>
      <td>2016-08-18</td>
    </tr>
    <tr>
      <th>859</th>
      <td>2016-08-19</td>
    </tr>
    <tr>
      <th>860</th>
      <td>2016-08-20</td>
    </tr>
    <tr>
      <th>861</th>
      <td>2016-08-21</td>
    </tr>
    <tr>
      <th>862</th>
      <td>2016-08-22</td>
    </tr>
  </tbody>
</table>
<p>863 rows × 1 columns</p>
</div>




```python
future = model_p.make_future_dataframe(periods=28)
future
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ds</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-04-13</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-04-14</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-04-15</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-04-16</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-04-17</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>858</th>
      <td>2016-08-18</td>
    </tr>
    <tr>
      <th>859</th>
      <td>2016-08-19</td>
    </tr>
    <tr>
      <th>860</th>
      <td>2016-08-20</td>
    </tr>
    <tr>
      <th>861</th>
      <td>2016-08-21</td>
    </tr>
    <tr>
      <th>862</th>
      <td>2016-08-22</td>
    </tr>
  </tbody>
</table>
<p>863 rows × 1 columns</p>
</div>




```python
prophet_forecast = model_p.predict(p_f_df)
prophet_forecast.tail(5)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ds</th>
      <th>trend</th>
      <th>yhat_lower</th>
      <th>yhat_upper</th>
      <th>trend_lower</th>
      <th>trend_upper</th>
      <th>additive_terms</th>
      <th>additive_terms_lower</th>
      <th>additive_terms_upper</th>
      <th>weekly</th>
      <th>weekly_lower</th>
      <th>weekly_upper</th>
      <th>yearly</th>
      <th>yearly_lower</th>
      <th>yearly_upper</th>
      <th>multiplicative_terms</th>
      <th>multiplicative_terms_lower</th>
      <th>multiplicative_terms_upper</th>
      <th>yhat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>858</th>
      <td>2016-08-18</td>
      <td>0.142120</td>
      <td>-19.007262</td>
      <td>18.975753</td>
      <td>0.142052</td>
      <td>0.142187</td>
      <td>0.650002</td>
      <td>0.650002</td>
      <td>0.650002</td>
      <td>0.476195</td>
      <td>0.476195</td>
      <td>0.476195</td>
      <td>0.173808</td>
      <td>0.173808</td>
      <td>0.173808</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.792122</td>
    </tr>
    <tr>
      <th>859</th>
      <td>2016-08-19</td>
      <td>0.142429</td>
      <td>-16.904982</td>
      <td>20.495302</td>
      <td>0.142359</td>
      <td>0.142501</td>
      <td>1.404169</td>
      <td>1.404169</td>
      <td>1.404169</td>
      <td>1.236801</td>
      <td>1.236801</td>
      <td>1.236801</td>
      <td>0.167367</td>
      <td>0.167367</td>
      <td>0.167367</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.546598</td>
    </tr>
    <tr>
      <th>860</th>
      <td>2016-08-20</td>
      <td>0.142739</td>
      <td>-18.467244</td>
      <td>20.562967</td>
      <td>0.142665</td>
      <td>0.142815</td>
      <td>0.799609</td>
      <td>0.799609</td>
      <td>0.799609</td>
      <td>0.638257</td>
      <td>0.638257</td>
      <td>0.638257</td>
      <td>0.161352</td>
      <td>0.161352</td>
      <td>0.161352</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.942348</td>
    </tr>
    <tr>
      <th>861</th>
      <td>2016-08-21</td>
      <td>0.143049</td>
      <td>-16.842757</td>
      <td>23.754646</td>
      <td>0.142970</td>
      <td>0.143128</td>
      <td>3.281748</td>
      <td>3.281748</td>
      <td>3.281748</td>
      <td>3.125697</td>
      <td>3.125697</td>
      <td>3.125697</td>
      <td>0.156051</td>
      <td>0.156051</td>
      <td>0.156051</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>3.424796</td>
    </tr>
    <tr>
      <th>862</th>
      <td>2016-08-22</td>
      <td>0.143358</td>
      <td>-18.856539</td>
      <td>16.017508</td>
      <td>0.143274</td>
      <td>0.143441</td>
      <td>-1.198332</td>
      <td>-1.198332</td>
      <td>-1.198332</td>
      <td>-1.350038</td>
      <td>-1.350038</td>
      <td>-1.350038</td>
      <td>0.151706</td>
      <td>0.151706</td>
      <td>0.151706</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>-1.054973</td>
    </tr>
  </tbody>
</table>
</div>




```python
fig = model_p.plot(prophet_forecast);

a = add_changepoints_to_plot(fig.gca(), model_p, prophet_forecast);
```


    
![png](output_88_0.png)
    


Measuring Prophet point forecast errors.


```python
calculate_prophet_error(df_test, prophet_forecast)
```

    me: -0.08736461727925873
    mae: 5.962703047165896
    mse: 57.67478722844032
    rmse: 7.5943918274237285
    mape: 144.62693988041093
    smape: 147.0330605955989



```python
model_p.plot_components(prophet_forecast);
```


    
![png](output_91_0.png)
    


From the decomposed prophet model components, we can see clearly that trend in the data set is rising steeply each day, and on a weekly basis there is alwas a deep on Tuesday, over the year, the seasonality flattens from May to early December which rises again on January.

### Cross validating Prophet model
To cross validate the prophet model, I used the cross validation procedures provided in the diagnostics module of the prophet package. I immported it as ``` from prophet.diagnostics import cross_validation, performance_metrics``` together with the performance metrics, passing in the following parameters, initial initial training length, period, and horizon in time delta.


```python
len(ts_diff)
```




    1044




```python
df_cv = cross_validation(model_p, initial=F'{str(3*28)} days', period='28 days', horizon='28 days')
```

    INFO:prophet:Making 26 forecasts with cutoffs between 2014-07-28 00:00:00 and 2016-06-27 00:00:00
    WARNING:prophet:Seasonality has period of 365.25 days which is larger than initial window. Consider increasing initial.



      0%|          | 0/26 [00:00<?, ?it/s]


    Initial log joint probability = -14.1648
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          92       36.8663    7.6779e-09       101.084      0.3789           1      126   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -22.8336
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          65       48.3639   4.90397e-06       100.975    4.86e-08       0.001      122  LS failed, Hessian reset 
          87       48.3642   8.32549e-09       99.4038      0.5334      0.5334      149   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -15.6559
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          76       76.8592   8.27228e-09       100.235      0.3622      0.3622      102   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -18.1794
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          81       89.2047   7.82237e-07       100.177   7.673e-09       0.001      146  LS failed, Hessian reset 
          96       89.2048   6.50406e-09       101.195      0.2213           1      168   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -19.7061
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          67       107.157   5.98057e-07        99.423   5.745e-09       0.001      123  LS failed, Hessian reset 
          74       107.157   8.21528e-09       102.718     0.09425     0.09425      132   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -31.9571
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          83       125.914   7.44391e-07       100.009   7.691e-09       0.001      151  LS failed, Hessian reset 
          99       125.914   3.22998e-08       99.5193           1           1      172   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         102       125.914   9.46666e-09       100.981      0.4157      0.4157      175   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -23.9088
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          72       137.017   1.62056e-07       105.038   1.572e-09       0.001      133  LS failed, Hessian reset 
          84       137.017   9.15715e-09       91.8386       0.428       0.428      147   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -25.6215
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       151.804   1.92315e-06       101.427           1           1      126   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         103       151.804   4.07175e-06       100.321   4.056e-08       0.001      166  LS failed, Hessian reset 
         139       151.805    9.4443e-07       100.783   9.398e-09       0.001      260  LS failed, Hessian reset 
         159       151.805   7.44091e-09       100.785      0.2298      0.2298      284   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -62.6093
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          91       196.701    7.8045e-07       99.4151   7.842e-09       0.001      155  LS failed, Hessian reset 
          99       196.701   8.60896e-08       100.226           1           1      165   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         105       196.701   9.15639e-09        98.488      0.4809      0.4809      174   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -26.0733
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          70       212.612   9.80066e-09       103.089       0.571       0.571       92   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -28.4367
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       232.691   8.44865e-05        103.84      0.7788      0.7788      118   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         199       233.192   7.01825e-08       99.3849           1           1      238   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         212       233.192   5.71218e-09       99.6931       0.781       0.781      254   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -28.5766
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          93       254.424   4.12444e-09       92.7279      0.4203      0.4203      123   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -30.0713
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          96       270.865    7.8022e-09        104.22       0.587       0.587      117   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -39.7066
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       286.395   5.20556e-07       85.8054      0.7704      0.7704      118   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         115       286.395   1.96849e-09       95.9008      0.1711      0.1711      141   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -33.9007
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          92       304.708   1.64085e-08       87.5381      0.3115           1      118   
    Optimization terminated normally: 
      Convergence detected: relative gradient magnitude is below tolerance
    Initial log joint probability = -50.5927
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          98       322.332   5.79456e-09       98.9907      0.1505      0.1505      126   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -38.5686
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       331.593   1.59961e-07       90.0293       0.221      0.5613      122   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         131       331.593   8.73982e-09       89.1494      0.1863           1      165   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -46.0195
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       353.041   7.53997e-08       96.7997      0.7593      0.7593      115   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         104       353.041   5.93919e-09       98.0858       0.278       0.278      121   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -65.3665
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          45       366.365    0.00103693        99.138   9.225e-06       0.001       90  LS failed, Hessian reset 
          99       366.903    0.00521984       99.5846           1           1      156   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         128       367.146   0.000348177       99.6403   3.117e-06       0.001      224  LS failed, Hessian reset 
         178       367.171   8.12329e-09       102.784      0.4225      0.4225      287   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -47.2172
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          84       389.265   5.10832e-09       100.335      0.3066      0.3066      106   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -122.205
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          74       403.174   0.000486175       103.035   5.029e-06       0.001      144  LS failed, Hessian reset 
          99       403.225    2.2766e-06        96.201      0.3486           1      175   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         125       403.225    7.0757e-09       100.356      0.2547      0.9096      206   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -62.7158
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          72        420.13   3.80937e-09       98.2514      0.3048      0.3048       92   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -62.6573
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          95       438.674   6.57153e-05       93.1691   7.497e-07       0.001      159  LS failed, Hessian reset 
          99        438.68   2.47114e-05       88.2297      0.2523           1      164   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         159       438.683   8.49093e-07       95.3995   8.752e-09       0.001      272  LS failed, Hessian reset 
         181       438.683   5.50541e-09       90.6834       0.346       0.346      304   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance
    Initial log joint probability = -71.2696
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       454.566   5.42545e-08       95.2143           1           1      126   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         110       454.566   1.75712e-08       93.1919       0.295           1      140   
    Optimization terminated normally: 
      Convergence detected: relative gradient magnitude is below tolerance
    Initial log joint probability = -53.4003
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       467.595   7.09389e-07       100.893      0.3557           1      120   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         119       467.595   2.21664e-08       90.4087       0.476       0.476      145   
    Optimization terminated normally: 
      Convergence detected: relative gradient magnitude is below tolerance
    Initial log joint probability = -102.523
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
          99       489.549   4.52613e-07       94.0213      0.7536      0.7536      121   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         118       489.638   0.000477116       100.673   4.432e-06       0.001      199  LS failed, Hessian reset 
         149       489.689   2.84453e-05       100.869   2.628e-07       0.001      274  LS failed, Hessian reset 
         172       489.696   2.82165e-05       106.225    2.69e-07       0.001      335  LS failed, Hessian reset 
         199       489.698   2.10768e-06       98.2488           1           1      365   
        Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes 
         201       489.701    8.0996e-06       100.004   8.049e-08       0.001      408  LS failed, Hessian reset 
         220       489.704    8.3298e-06       102.743   8.611e-08       0.001      467  LS failed, Hessian reset 
         244       489.721   5.91098e-05       100.495   5.445e-07       0.001      531  LS failed, Hessian reset 
         274       489.725   2.45466e-09        93.886      0.1097      0.1097      571   
    Optimization terminated normally: 
      Convergence detected: absolute parameter change was below tolerance



```python
df_cv.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ds</th>
      <th>yhat</th>
      <th>yhat_lower</th>
      <th>yhat_upper</th>
      <th>y</th>
      <th>cutoff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2014-07-29</td>
      <td>-3.304975</td>
      <td>-24.404518</td>
      <td>15.450410</td>
      <td>6.500000</td>
      <td>2014-07-28</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2014-07-30</td>
      <td>-0.962852</td>
      <td>-19.908424</td>
      <td>17.540469</td>
      <td>-13.000000</td>
      <td>2014-07-28</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2014-07-31</td>
      <td>0.702830</td>
      <td>-18.026444</td>
      <td>19.121641</td>
      <td>9.833333</td>
      <td>2014-07-28</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2014-08-01</td>
      <td>0.228410</td>
      <td>-18.495642</td>
      <td>19.792798</td>
      <td>-4.083333</td>
      <td>2014-07-28</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2014-08-02</td>
      <td>0.781026</td>
      <td>-18.162021</td>
      <td>19.737696</td>
      <td>-11.166667</td>
      <td>2014-07-28</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_p = performance_metrics(df_cv, rolling_window=1)
df_p
```

    INFO:prophet:Skipping MAPE because y close to 0





<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>horizon</th>
      <th>mse</th>
      <th>rmse</th>
      <th>mae</th>
      <th>mdape</th>
      <th>smape</th>
      <th>coverage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>28 days</td>
      <td>115.815522</td>
      <td>10.761762</td>
      <td>8.808689</td>
      <td>1.047357</td>
      <td>1.540883</td>
      <td>0.931319</td>
    </tr>
  </tbody>
</table>
</div>




```python

```


```python
fig = plot_cross_validation_metric(df_cv, metric='rmse', rolling_window=0.1)
```

    /home/ubuntu/anaconda3/envs/hds_forecast/lib/python3.8/site-packages/prophet/plot.py:539: FutureWarning: casting timedelta64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.
      x_plt = df_none['horizon'].astype('timedelta64[ns]').astype(np.int64) / float(dt_conversions[i])
    /home/ubuntu/anaconda3/envs/hds_forecast/lib/python3.8/site-packages/prophet/plot.py:540: FutureWarning: casting timedelta64[ns] values to int64 with .astype(...) is deprecated and will raise in a future version. Use .view(...) instead.
      x_plt_h = df_h['horizon'].astype('timedelta64[ns]').astype(np.int64) / float(dt_conversions[i])



    
![png](output_99_1.png)
    


# Results
As seen from the above-predicted output of the Naive1 forecast, it has predicted that the number of pediatrics emergency attendance for the next 28 days would be constant at 5.25 an equivalent of 61 according to the training data if converted back to an original state, with an estimated point forecast error of mean absolute error(MAE) = 9.40, root mean square error(RMSE) = 11.41, and symmetric mean absolute percentage error (SMAPE) = 139.45, cross-validation average root mean square error(RMSE)=13.62. Seasonal Naive forecast cored point forecast errors of mean absolute error(MEA) = 10.10, root mean square error(RMSE) = 13.69, symmetric mean absolute percentage error(SMAPE) = 140.84, and an average root mean square error(RMSE)=13.55 during cross-validation. Prophet models scored point forecast errors of mean absolute error(MEA) = 5.96, root mean square error(RMSE) = 7.59, symmetric mean absolute percentage error(SMAPE) = 147.03, and an average of 10.76 root mean square error(RMSE) with cross validation respectively.


Checking other baseline estimators with a cross validation score to establish if there is one that may be better than prophet in terms of the cross validate root mean square error(RMSE).


```python
# from forecast_tools.baseline import baseline_estimators
estimators = baseline_estimators(seasonal_period=12)
estimators
```




    {'NF1': Naive1(),
     'SNaive': SNaive1(period=12),
     'Average': Average(),
     'Drift': Drift(),
     'Ensemble': EnsembleNaive(seasonal_period=12)}




```python
min_train_size = 200

results = {}
combined_scores = []
for name, model in estimators.items():
    cv = rolling_forecast_origin(train1, 
                                 min_train_size=min_train_size, 
                                 horizon=28)
    scores = cross_validate(model, cv)
    results[name] = scores
    combined_scores.append(scores)
    
results
```

    13.570269375459477
    13.678356863518225
    12.95630650927927
    13.086683980447223
    12.860261026467784





    {'NF1': None, 'SNaive': None, 'Average': None, 'Drift': None, 'Ensemble': None}



# Discussion And Conclusion
From the results obtained above from the three methods, Naive1, SNaive, and Prophet, SNaive produced the highest point forecast error concerning mean absolute error(MAE), root mean square error((RMSE), its symmetric mean absolute percentage error(SMAPE) was also higher than that of Naive1 model but prophet model. This means overall it had the lowest accuracy in its predicted values than the other two methods, followed by Naive1 forecast method as its error scores were second-highest among the three methods. Prophet scored the least error scores except for its symmetric mean absolute percentage error, this implies prophet had a higher level of accuracy in forecasting the future number of pediatrics attendance for the next twenty-eight days, Although its symmetric mean absolute percentage error was high, this could be due to the nature of the data that may not easily be evaluated using relative methods. Prophets give a clear breakdown of its diagnostics and decomposed components which revealed clearly that on a weekly scale there is always a dip every Tuesday, on a daily scale there is an increasing number of patients as depicted by the upward trend. To predict the future prophet makes a simulated future data, Snaive recalls a previous particular day of the week number and uses it to predict the next value on that particular weekday of the following week and so on for monthly data, which is not true in reality. The naive1 method carries the last value in the time series throughout the horizon to forecast the future which is so erroneous in reality. So for this time-series data set, I strongly recommend the prophet forecasting method as it produced the least error score both at cross-validation and for point forecast error, more so its algorithm is additive regression with four components of linear or logistic regression and can detect trends automatically in data by changing data points.



